---
title: "ISA 401/501: Business Intelligence & Data Visualization"
subtitle: '05: Scraping Multiple Webpages in `r icons::icon_style(icons::fontawesome("r-project"), fill = "white")`'
author: '<br>Fadel M. Megahed, PhD <br><br> Enders Associate Professor <br> Farmer School of Business<br> Miami University<br><br> [`r icons::icon_style(icons::fontawesome("twitter"), fill = "white")` @FadelMegahed](https://twitter.com/FadelMegahed) <br> [`r icons::icon_style(icons::fontawesome("github"), fill = "white")` fmegahed](https://github.com/fmegahed/) <br> [`r icons::icon_style(icons::fontawesome("paper-plane", style = "solid"), fill = "white")` fmegahed@miamioh.edu](mailto:fmegahed@miamioh.edu)<br> [`r icons::icon_style(icons::fontawesome("question"), fill = "white")` Automated Scheduler for Office Hours](https://calendly.com/fmegahed)<br><br>'
date: "Fall 2022"
output:
  xaringan::moon_reader:
    self_contained: true
    css: [default, "../../style_files/fonts.css", "../../style_files/my-theme.css"]
    lib_dir: libs
    nature:
      highlightStyle: magula
      highlightLines: true
      highlightLanguage: ["r"]
      countIncrementalSlides: false
      ratio: "16:9"
header-includes:  
  - "../../style_files/header.html"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE,
                      echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      progress = FALSE, 
                      verbose = FALSE,
                      dev = 'png',
                      fig.height = 2.5,
                      dpi = 300,
                      fig.align = 'center')

options(htmltools.dir.version = FALSE)

miamired = '#C3142D'

if(require(pacman)==FALSE) install.packages("pacman")
if(require(devtools)==FALSE) install.packages("devtools")

if(require(countdown)==FALSE) devtools::install_github("gadenbuie/countdown")
if(require(xaringanExtra)==FALSE) devtools::install_github("gadenbuie/xaringanExtra")


pacman::p_load(tidyverse, magrittr, lubridate, janitor, # data analysis pkgs
               rvest, # for scraping
               scales, # for the comma function
               gifski, av, # for animations
               fontawesome, RefManageR, xaringanExtra, countdown) # for slides

BibOptions(check.entries = FALSE, bib.style = "authoryear", 
           style = "markdown", dashed = TRUE)

bib = ReadBib("refs.bib") 
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
if(require(xaringanthemer) == FALSE) install.packages("xaringanthemer")
library(xaringanthemer)

style_mono_accent(base_color = "#84d6d3",
                  base_font_size = "20px")

xaringanExtra::use_xaringan_extra(c("tile_view", "animate_css", "tachyons", "panelset", "broadcast", "share_again", "search", "fit_screen", "editable", 
                                    "clipable"))

```


# Quick Refresher from Last Class

`r emo::ji("check")` Understand when can we scrape data (i.e., `robots.txt`)    

`r emo::ji("check")` Scrape a webpage using `r fontawesome::fa("r-project", fill = miamired)`

---

# Kahoot Competition #2

To assess your understanding and retention of the topics covered last week, you will **compete in a Kahoot competition (consisting of 5 questions)**:  

- Go to <https://kahoot.it/>  

- Enter the game pin, which will be shown during class

- Provide your first (preferred) and last name

- Answer each question within the allocated time-window (**fast and correct answers provide more points**)

**Winning the competition involves having as many correct answers as possible AND taking the shortest duration to answer these questions.** The winner `r fontawesome::fa(name = 'trophy', fill = 'gold')` of the competition from each section will receive: $10 Starbucks gift card. Good luck!!!

.footnote[
<html>
<hr>
</html>

**P.S:** The Kahoot competition will have **no impact on your grade**. It is a **fun** way of assessing your knowledge, motivating you to ask questions about topics covered that you do not have a full understanding of it, and providing me with some data that I can use to pace today's class. 
]

---


# Going Over Assignment 04 Solutions

.panelset[

.panel[.panel-name[Q1]

.small[Use the `robotstxt` `r fontawesome::fa("r-project", fill = miamired)` package to examine whether <https://www.yelp.com/biz/pattersons-cafe-oxford> can be scraped per our discussion in class. You should store the output from the `robotstxt::paths_allowed()` function in an object with the name of `yelp_robots`]

]


.panel[.panel-name[Q2]

.small[
Go to the webpage <https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true> which contains Miami University's Lost and Found Database and write an `r fontawesome::fa("r-project", fill = miamired)` script that will scrape the contents of the table in the spreadsheet. You should save the tibble/data.frame of the results (NOT a list) in an object with the name of `lost_found`]

]

.panel[.panel-name[Q3]

.small[
Go to <https://www.miamioh.edu/fsb/academics/isa/about/faculty-staff/index.html> and write an `r fontawesome::fa("r-project", fill = miamired)` script that will scrape the three column table containing faculty and staff information. You should save the tibble/data.frame of the results (NOT a list) in an object with the name of `isa_fac`] 

]

.panel[.panel-name[Q4]
.small[
The most popular listings on Netflix are rated and reviews on ImDb are available at <https://www.imdb.com/search/title/?companies=co0144901>. Write an `r fontawesome::fa("r-project", fill = miamired)` script that will produce a tibble that contains the following:

- title, which you will save in a column titled `title`  
- year/years of show, which you will save in a column titled `year`  
- 1-2 sentence summary of show, which you save in a column titled `summary`  

The tibble containing these three columns should have the name of `netflix`. Please make sure that you do not overwrite `netflix` at any point of the code.

]

]
]


---

# Learning Objectives for Today's Class

- Understand when can we scrape data (i.e., `robots.txt`)  

- Scrape multiple webpages using `r fontawesome::fa("r-project", fill = miamired)` 

- Use loops and/or tidymodeling approaches to scrape data from multiple webpages

---

class: middle, inverse, center


# Web Scraping Demos (Cont.)


---

# Cleaning Up the Output from your Non-Graded Class Activity


.panelset[

.panel[.panel-name[Activity]

.small[
- Go to [this database on plane crashes](http://www.planecrashinfo.com/2022/2022.htm)  

- Scrape the HTML table. **Note the difference from text elements:**  
  + The CSS selector for `html_elements()` will be different.  
  + You will extract a table (in its **entirety**) and hence:  
    * we will use `html_table()` instead of `html_text2()`

- Store the scraped data in an appropriate location on your computer (e.g., within the data folder for ISA 401)
]
]


.panel[.panel-name[My Solution]

**Please refer to our discussion in class**

]
]

---

# Demo 2:  Scraping all Plane Crashes 2013-2022

- We will build on the previous example and we will scrape all the plane crashes that were recorded in the [plane crash database](http://www.planecrashinfo.com/) between 2013-2022. 

- Then, we will create a single **tibble** for all crashes. It will contain the fields in the individual tables as well as the year of crash.

- Then, we will **export the results to a CSV** so that we can analyze that in a separate program if we wanted to.


---

# Demo 3: Scraping the first 300 entries in IMDB

The most popular listings on Netflix are rated and reviews on ImDb are available at <https://www.imdb.com/search/title/?companies=co0144901>. Write an `r fontawesome::fa("r-project", fill = miamired)` script that will produce a tibble that contains the **following information for the first 300 entries**:

- title, which you will save in a column titled `title`  
- year/years of show, which you will save in a column titled `year`  
- 1-2 sentence summary of show, which you save in a column titled `summary`  


---

# Demo 4: Downloading the Lecture PDFs (if time allows)

If time allows, we will download all the [ISA 401 lecture pdf-slides from GitHub](https://github.com/fmegahed/isa401/tree/main/pdfs) using an `r fontawesome::fa("r-project", fill = miamired)` script.




---

class: inverse, center, middle

# Recap

---

# Summary of Main Points

By now, you should be able to do the following:

- Understand when can we scrape data (i.e., `robots.txt`)  

- Scrape multiple webpages using `r fontawesome::fa("r-project", fill = miamired)` 

- Use loops and/or tidymodeling approaches to scrape data from multiple webpages


---

# Things to Do to Prepare for Next Class

- Go over your notes, read through the supplementary material (below), go through the [self-paced tutorial](http://rstudio.fsb.miamioh.edu:3838/megahefm/isa401/webscraping/) and complete [Assignment 05](https://miamioh.instructure.com/courses/179812/assignments/2218207) on Canvas. 

.pull-left[
.center[
```{r paper_1, echo=FALSE, out.height="300px"}
knitr::include_graphics("../../figures/web_scrape_in_data_science.PNG", dpi = NA)
```
]
* [PDF of Published Paper](https://www.tandfonline.com/doi/pdf/10.1080/10691898.2020.1787116)
* [ePub of Published Paper](https://www.tandfonline.com/doi/epub/10.1080/10691898.2020.1787116?needAccess=true)
]
.pull-right[
.center[<img src="https://github.com/rstudio/hex-stickers/raw/master/PNG/rvest.png" height="300px">]
* [Selector Gadget](https://rvest.tidyverse.org/articles/articles/selectorgadget.html)  
* [Getting Started with rvest](https://rvest.tidyverse.org/articles/articles/selectorgadget.html)  

* [Practical Web Scraping in R](https://www.r-bloggers.com/2019/04/practical-introduction-to-web-scraping-in-r/)
]

