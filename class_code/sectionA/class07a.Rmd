---
title: "Assignments 4 and 5 Walkthrough"
author: "Fadel Megahed"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: TRUE
    toc: TRUE
    toc_float: TRUE
    code_folding: show
    code_download: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Q2 HW 04

```{r lost_and_found}
"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  rvest::read_html() |> 
  rvest::html_elements("table") |>  # table or table.waffle
  rvest::html_table() |> 
  magrittr::extract2(1) -> q2_answer

colnames(q2_answer) = q2_answer[1, ] # row, empty (means all columns)

q2_answer = q2_answer[-c(1, 2), -1 ] # optional step for cleaning the answer
q2_answer$`Date Found / Impounded / Turned into MU Police Dept` = lubridate::mdy(q2_answer$`Date Found / Impounded / Turned into MU Police Dept`)

dplyr::glimpse(q2_answer)

```


# Q4

```{r imdb}
imdb_page = rvest::read_html("https://www.imdb.com/search/title/?companies=co0144901")

titles = imdb_page |> rvest::html_elements("h3 a") |> rvest::html_text2()

years = imdb_page |> rvest::html_elements("h3 span") |> rvest::html_text2()
rankings = years[seq(1, 100, 2)]
years = years[-seq(1, 100, 2)] # alternatively positive of seq(2, 100, 2)

summary1 = imdb_page |> rvest::html_elements("div p") |> rvest::html_text2()
summary1 = summary1[seq(2, 200, 4)]

netflix_df = tibble::tibble(
  rankings, titles, years, summary1
)

summary2 = imdb_page |>
  rvest::html_elements("#main > div > div.lister.list.detail.sub-list > div > div > div.lister-item-content > p:nth-child(4)") |> 
  rvest::html_text2()
```



# HW 5

```{r}
fsb_urls = c("https://miamioh.edu/fsb/directory/?up=/query/all/all/Information%20Systems%20--%20Analytics/all", "https://miamioh.edu/fsb/directory/?up=/query/all/all/Finance/all")

# First step do it for one webpage

fac_page = rvest::read_html(fsb_urls[1])

# element instead of elements since there is only one table and this will
# eliminate the need for the magrittr::extract2()
fac_table = fac_page |> rvest::html_element("table") |> rvest::html_table()

# Given that for this webpage, I did not get what I want I will attempt to read (almost) every column separately

dep = fac_table$Department # since this column was fine

names = fac_page |> 
  rvest::html_elements("td:nth-child(3) > strong > a") |> rvest::html_text2()

titles = fac_page |> 
  rvest::html_elements("td:nth-child(3) > i") |> rvest::html_text2()

hyperlinks <-
  fac_page  |> # for this code to work, you also need to end the element/node at a
  rvest::html_elements("strong > a") |> # either use the nodes or elements func
  rvest::html_attr("href") # this is the name of the attribute that you are pulling

df = tibble::tibble(dep, names, titles, links = hyperlinks)

# Now let us create our function
scrape_miami = function(mu_url){
  fac_page = rvest::read_html(mu_url)
  
  fac_table = fac_page |> rvest::html_element("table") |> rvest::html_table()
  
  dep = fac_table$Department 
  
  names = fac_page |> 
    rvest::html_elements("td:nth-child(3) > strong > a") |> rvest::html_text2()
  
  titles = fac_page |> 
    rvest::html_elements("td:nth-child(3) > i") |> rvest::html_text2()
  
  hyperlinks <-
    fac_page  |> # for this code to work, you also need to end the element/node at a
    rvest::html_elements("strong > a") |> # either use the nodes or elements func
    rvest::html_attr("href") # this is the name of the attribute that you are pulling
  
  df = tibble::tibble(dep, names, titles, links = hyperlinks)
  
  return(df)
}

fsb_df = purrr::map_df(.x = fsb_urls, .f = scrape_miami)

```

