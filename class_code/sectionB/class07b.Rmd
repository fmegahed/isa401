---
title: "Walk through of Assignments 4 and 5"
author: "Fadel Megahed"
date: "`r Sys.Date()`"
output: 
  html_document:
    number_sections: TRUE
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 04

## Q2

```{r lost_found}
"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  # get the webpage into R
  rvest::read_html() |> 
  # select/parse what you are interested in ( i have a single table)
  rvest::html_elements("table") |> 
  # tables we clean them using html_table()
  rvest::html_table() -> q2a

q2a = q2a[[1]] # subset the list and convert it into its underlying data structure

colnames(q2a) = q2a[1, ] # assign that to row 1 (before the comma), all columns (after comma is empty)

# everything from here down is optional if and only if you are not doing further analysis
q2a_1 = q2a[3:73, 2:5]
q2a_1$`Date Found / Impounded / Turned into MU Police Dept` = lubridate::mdy(q2a_1$`Date Found / Impounded / Turned into MU Police Dept`)

dplyr::glimpse(q2a_1)

q2a_2 = q2a[-c(1,2), -1] # then proceed to fix column types


# showing you how to use the extract2()
"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  # get the webpage into R
  rvest::read_html() |> 
  # select/parse what you are interested in ( i have a single table)
  rvest::html_elements("table") |> 
  # tables we clean them using html_table()
  rvest::html_table() |> 
  magrittr::extract2(1) -> q2b
# proceed as above

# showing you how to use the extract2()
"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  # get the webpage into R
  rvest::read_html() |> 
  # select/parse what you are interested in ( i have a single table)
  rvest::html_element("table") |> # bec its one table
  # tables we clean them using html_table()
  rvest::html_table()  -> q2c
# proceed as above

"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  # get the webpage into R
  rvest::read_html() |> 
  # select/parse what you are interested in ( i have a single table)
  rvest::html_element("table.waffle") |> # bec its one table
  # tables we clean them using html_table()
  rvest::html_table()  -> q2d

"https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true" |> 
  # get the webpage into R
  rvest::read_html() |> 
  # select/parse what you are interested in ( i have a single table)
  rvest::html_element("div > table") |> # bec its one table
  # tables we clean them using html_table()
  rvest::html_table()  -> q2e

```


## Q4

```{r imdb}
imdb_page = rvest::read_html("https://www.imdb.com/search/title/?companies=co0144901")

titles = imdb_page |> 
  rvest::html_elements("#main > div > div.lister.list.detail.sub-list > div > div > div.lister-item-content > h3 > a") |> # alternatively h3 > a or any selector that is larger than that will give you the same answer but not including that nth-child that was removed
  rvest::html_text2()

titlesb = imdb_page |> 
  rvest::html_elements(css = "h3 a") |> # based on tweaking the selector gadget
  rvest::html_text2()

titlesc = imdb_page |> 
  rvest::html_elements(css = "h3 a") |> # based on tweaking the selector gadget
  rvest::html_text()

titlesd = imdb_page |> 
  rvest::html_elements("div.lister-item-content > h3 > a") |> # alternatively h3 > a or any selector that is larger than that will give you the same answer
  rvest::html_text2()

years = imdb_page |> 
  rvest::html_elements(".unbold") |> 
  rvest::html_text2()

popularity = years[seq(1, 100, 2)]
years = years[seq(2, 100, 2)]

summary = imdb_page |> 
  rvest::html_elements("div p") |> 
  rvest::html_text2()

summary = summary[seq(2,200,4)]

summary2 = imdb_page |> 
  rvest::html_elements("div.lister-item-content > p:nth-child(4)") |> 
  rvest::html_text2()


netflix_df = tibble::tibble(popularity, titles, years, summary2)

netflix_df
```


# Assignment 5

```{r}
fsb_urls = c('https://miamioh.edu/fsb/directory/?up=/query/all/all/Information%20Systems%20--%20Analytics/all', "https://miamioh.edu/fsb/directory/?up=/query/all/all/Accountancy/all")

fsb_page = rvest::read_html(fsb_urls[1])

hard_solution = fsb_page |> rvest::html_element("#sidebar-main > div > table") |> rvest::html_table()

# lazily getting it from the first step (you do not have to do that for sure)
dept = hard_solution$Department

names = fsb_page |> rvest::html_elements("strong a") |> rvest::html_text2()
titles = fsb_page |> rvest::html_elements("i") |> rvest::html_text2()

# ChatGPT/ChatISA/Google
fac_urls = fsb_page |> 
  rvest::html_nodes("strong a") |> # needs to ends with a
  rvest::html_attr("href")

df = tibble::tibble(department = dept, 
                    names, titles, fac_urls)

# my function
fsb_urls = c('https://miamioh.edu/fsb/directory/?up=/query/all/all/Information%20Systems%20--%20Analytics/all', "https://miamioh.edu/fsb/directory/?up=/query/all/all/Accountancy/all")

scrape_miami = function(fsb_url){
  fsb_page = rvest::read_html(fsb_url)
  
  hard_solution = fsb_page |> rvest::html_element("#sidebar-main > div > table") |> rvest::html_table()
  
  # lazily getting it from the first step (you do not have to do that for sure)
  dept = hard_solution$Department
  
  names = fsb_page |> rvest::html_elements("strong a") |> rvest::html_text2()
  titles = fsb_page |> rvest::html_elements("i") |> rvest::html_text2()
  
  # ChatGPT/ChatISA/Google
  fac_urls = fsb_page |> 
    rvest::html_nodes("strong a") |> # needs to ends with a
    rvest::html_attr("href")
  
  df = tibble::tibble(department = dept,  names, titles, fac_urls)
  
  return(df)
}

fsb_results = purrr::map_df(.x = fsb_urls, .f = scrape_miami)
```

