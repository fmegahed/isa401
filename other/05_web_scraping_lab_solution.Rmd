---
title: "Lab 1: Scraping Web Pages (Solution)"
author:
  - name: "Fadel Megahed ^[Email: fmegahed@miamioh.edu]"
    affiliation: Farmer School of Business, Miami University
date: "Spring 2022"
output: 
  html_document:
    code_folding: show
    code_download: TRUE
    number_sections: TRUE
    paged_df: TRUE
    toc: TRUE
    toc_float: TRUE
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      progress = FALSE,
                      verbose = TRUE,
                      cache = TRUE)
```


---

# Required Packages
```{r packages}
# checking to see if the pacman package is installed + installing it if needed
if(require(pacman)==FALSE) install.packages("pacman")
pacman::p_load(tidyverse, 
               magrittr,
               rvest,
               lubridate,
               DT)
```


---

# Scraping the Miami University Found and Impounded Property Listing

When you click on [Found and Impounded Property Listing](https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true) on the [Property - Lost, Found, Impounded Page](https://www.miamioh.edu/police/services/propertylostfoundimpounded/index.html), you will be taken to a Google Doc containing a table of lost and found items. 

**Please scrape the table and print it out.** Your code should be self-contained in the code chunk below.

```{r mu_lost_and_found}
google_doc_page = read_html("https://docs.google.com/spreadsheets/d/e/2PACX-1vQ3uk9AJOMODxS9fUgX_4vnEMj-Di7ulkTXWzPUmaHvHbaII63xmKmRu3VaBvOXrwQhtkOUlL9fxLMB/pubhtml?gid=1104208671&single=true")

google_doc_page %>% 
  html_elements("table.waffle") %>% html_table(header = 1) %>% .[[1]] -> lost_and_found_list

colnames(lost_and_found_list) = lost_and_found_list[1, ]

lost_and_found_list = lost_and_found_list[-c(1,2), ]
colnames(lost_and_found_list)[1] = 'obs_number'
lost_and_found_list[1:nrow(lost_and_found_list), 1] = 1:nrow(lost_and_found_list)

lost_and_found_list$`Date Found / Impounded / Turned into MU Police Dept` %<>% mdy()

lost_and_found_list %>% DT::datatable()

```


---

# Create a Table of all FSB Departmental Faculty/Staff

Currently, the Farmer School of Business has the following academic departments:  
- [Accountancy](https://www.miamioh.edu/fsb/academics/accountancy/about/faculty-staff/index.html)  
- [Economics](https://www.miamioh.edu/fsb/academics/economics/about/faculty-staff/index.html)   
- [Entrepreneurship](https://www.miamioh.edu/fsb/academics/entrepreneurship/about/faculty-staff/index.html)  
- [Finance](https://www.miamioh.edu/fsb/academics/finance/about/faculty-staff/index.html)
- [Information Systems & Analytics](https://www.miamioh.edu/fsb/academics/isa/about/faculty-staff/index.html)  
- [Marketing](https://www.miamioh.edu/fsb/academics/marketing/about/faculty-staff/index.html)  
- [Management](https://www.miamioh.edu/fsb/academics/management/about/faculty-staff/index.html)  

Using the code chunk below, please write code that will produce and print a **single tibble containing information on ALL departments and the following variables:** (a) department name, (b) faculty/staff's name, (c) faculty/staff's position, and (d) faculty/staff's website

```{r fsb_faculty_staff}
urls = c('https://www.miamioh.edu/fsb/academics/accountancy/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/economics/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/entrepreneurship/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/finance/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/isa/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/marketing/about/faculty-staff/index.html',
         'https://www.miamioh.edu/fsb/academics/management/about/faculty-staff/index.html')

scrape_miami = function(x){
 fsb_page = x %>% read_html()

dept_name = fsb_page %>% html_elements('tr > td:nth-child(1)') %>% html_text2()

faculty_name = fsb_page %>% html_elements('tr > td:nth-child(3) > strong > a') %>% html_text2()

faculty_title = fsb_page %>% html_elements('tr > td:nth-child(3) > i') %>% html_text2()
faculty_title %<>% str_replace(pattern = '\n', replacement = ' ')

faculty_webpage = fsb_page %>% 
  html_elements('tr > td:nth-child(3) > strong > a') %>% html_attr(name = 'href')

dept_tibble = tibble(dept_name, faculty_name, faculty_title, faculty_webpage) 

return(dept_tibble)
}

fsb_tibble = map_df(.x = urls, .f = scrape_miami)

fsb_tibble %>% DT::datatable()

```


---

# Netflix Ratings on IMDb

The most popular listings on Netflix are rated and reviews on [ImDb](https://www.imdb.com/search/title/?companies=co0144901). Based on this webpage and its following pages, please create a **tibble** that contains the following:

- *Title:*  
- *Years:*
- *Age classification:*
- *Duration:*
- *Genres:*
- *IMDb Rating:*
- *1-2 Sentence Summary:*
- *Stars:*
- *Votes:*

**Your tibble should contain a variable for the 9 items above for each of the 50 titles found on the page.** 

```{r netflix_imdb_p1}
imdb_pg = read_html('https://www.imdb.com/search/title/?companies=co0144901')

title = imdb_pg %>% html_elements('h3 > a') %>% html_text2()
years = imdb_pg %>% html_elements('h3 > span.lister-item-year.text-muted.unbold') %>% html_text2()

age_classification = imdb_pg %>% html_elements('span.certificate') %>% html_text2()
duration = imdb_pg %>% html_elements('span.runtime') %>% html_text2()
genres = imdb_pg %>% html_elements('span.genre') %>% html_text2()


imdb_ratings = imdb_pg %>% html_elements('div > div.inline-block.ratings-imdb-rating > strong') %>% html_text2() %>% as.numeric()

summary = imdb_pg %>% html_elements('div.lister-item-content > p:nth-child(4)') %>% html_text2()

stars = imdb_pg %>% html_elements('div.lister-item-content > p:nth-child(5)') %>% html_text2()

votes = imdb_pg %>% html_elements('p.sort-num_votes-visible > span:nth-child(2)') %>% html_text2()

imdb_tibble = tibble(title, years, age_classification, genres, 
                     imdb_ratings, summary, stars, votes)


# optional to try to figure out how to incorporate NAs in the correct location
# for the duration column
age_duration_genre = imdb_pg %>% html_elements('div.lister-item-content > p:nth-child(2)') %>% html_text2() %>% str_split(pattern = '\\|')

length_sublists = map_dbl(.x = age_duration_genre, .f = length)
index = which(length_sublists < 3)

temp = duration
for (i in 1:length(index)) {
  temp = append(temp, values = NA, after = index[i] -1)
  print("__________")
  print(temp)
  print("__________")
}

duration = temp


imdb_tibble = tibble(title, years, age_classification, duration, genres, 
                     imdb_ratings, summary, stars, votes)
imdb_tibble %>% DT::datatable()

```

---

# Top 300 Netflix Ratings 

Expand on the previous example to capture the top **300** titles on Netflix (i.e., the information across six pages).

```{r netflix_imdb_p2}
netflix_urls = paste0('https://www.imdb.com/search/title/?companies=co0144901&start=',
                      seq(from=1, to = 300, by = 50), '&ref_=adv_nxt')

title_vec = years_vec = age_classification_vec = duration_vec = genres_vec =
  imdb_ratings_vec = summary_vec = stars_vec = votes_vec = vector()

for (i in 1:length(netflix_urls)) {
  imdb_pg = read_html(netflix_urls[i])
  
  title = imdb_pg %>% html_elements('h3 > a') %>% html_text2()
  years = imdb_pg %>% html_elements('h3 > span.lister-item-year.text-muted.unbold') %>% html_text2()
  
  age_classification = imdb_pg %>% html_elements('span.certificate') %>% html_text2()
  duration = imdb_pg %>% html_elements('span.runtime') %>% html_text2()
  genres = imdb_pg %>% html_elements('span.genre') %>% html_text2()
  
  
  imdb_ratings = imdb_pg %>% html_elements('div > div.inline-block.ratings-imdb-rating > strong') %>% html_text2() %>% as.numeric()
  
  summary = imdb_pg %>% html_elements('div.lister-item-content > p:nth-child(4)') %>% html_text2()
  
  stars = imdb_pg %>% html_elements('div.lister-item-content > p:nth-child(5)') %>% html_text2()
  
  votes = imdb_pg %>% html_elements('p.sort-num_votes-visible > span:nth-child(2)') %>% html_text2()
  
  print('_____________________________________________')
  print( paste0('We are currently in iteration ', i) )
  
  title_vec = c(title_vec, title)
  years_vec = c(years_vec, years)
  age_classification_vec = c(age_classification_vec, age_classification)
  duration_vec = c(duration_vec, duration)
  genres_vec = c(genres_vec, genres_vec)
  imdb_ratings_vec = c(imdb_ratings_vec, imdb_ratings)
  summary_vec = c(summary_vec, summary)
  stars_vec = c(stars_vec, stars)
  votes_vec = c(votes_vec, votes)
  
  print(
    paste('Length of titles, years, age_classification, duration, genres, ratings, summary, stars and votes is',
           length(title), length(years), length(age_classification), length(duration),
           length(genres), length(imdb_ratings), length(summary), length(stars), length(votes),
    sep = ', ')
  )
  
}

tibble(title_vec, years_vec, summary_vec) %>% DT::datatable()
```


---

# Yelp Reviews for Patterson Cafe
In assignment 02, I shared with you an RDS file containing four variables and all the reviews that were performed on [Patterson Cafe on Yelp](https://www.yelp.com/biz/pattersons-cafe-oxford). Use what you have learned in class to potentially recreate the same results.

```{r yelp_reviews}
pacman::p_load(robotstxt)

paths_allowed(domain = 'https://www.yelp.com', paths = '/biz/pattersons-cafe-oxford')
paths_allowed(domain = 'https://www.yelp.com', paths = '/biz/')
```

